{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c861519b-827b-4071-8c69-a69722bf1d2a",
   "metadata": {},
   "source": [
    "# Summary of Project Goals and Results\n",
    "\n",
    "The primary objective of this project was to develop and compare two advanced deep learning models‚ÄîConvolutional Neural Networks (CNNs) and ResNet‚Äîfor image classification on the CIFAR-10 dataset. Both models were trained and evaluated to identify 10 object categories with high precision. Key findings include:\n",
    "\n",
    "- CNN models initially struggled with overfitting but improved significantly after applying dropout and early stopping techniques.\n",
    "- The fine-tuned ResNet model demonstrated superior generalization, achieving a validation accuracy of 87.7% and a test accuracy of 86.75%.\n",
    "\n",
    "**Overall, ResNet outperformed CNN in terms of generalization and accuracy, making it the better choice for this classification task.** Its ability to maintain high performance on unseen test data reflects its robustness and suitability for complex image classification challenges.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2092a56-d3d4-4f53-b4d1-01574b8994d1",
   "metadata": {},
   "source": [
    "# Implications and Potential Applications\n",
    "\n",
    "The findings underscore the practicality of using CNNs and ResNet for real-world image recognition tasks such as:\n",
    "\n",
    "- Autonomous vehicle systems, where accurate object identification is critical.\n",
    "- Medical imaging for detecting patterns in diagnostic scans.\n",
    "- Consumer applications like content categorization and visual search.\n",
    "\n",
    "This project also demonstrates the importance of optimization techniques, such as dropout and early stopping, in enhancing model performance and reliability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3a7a61-6333-4bf9-8ee6-00d87fbe97c9",
   "metadata": {},
   "source": [
    "# Recommendations for Future Work\n",
    "\n",
    "While this study achieved promising results, several areas for further refinement and exploration remain:\n",
    "\n",
    "1. **Hyperparameter Optimization**: Conduct a more extensive hyperparameter search to fine-tune learning rates, batch sizes, and layer configurations.\n",
    "2. **Data Augmentation**: Apply advanced augmentation techniques (e.g., mixup, cutout) to improve model robustness.\n",
    "3. **Model Ensemble**: Combine predictions from CNN and ResNet models to further boost classification accuracy.\n",
    "4. **Transfer Learning**: Explore pre-trained architectures for faster convergence and potentially higher performance.\n",
    "5. **Expanded Dataset**: Test models on more diverse datasets to evaluate their scalability and adaptability.\n",
    "\n",
    "By addressing these areas, future iterations of this project could push the boundaries of image classification accuracy and extend its applicability across a wider range of domains.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd37bd7-320b-4edb-948e-d4079b244d78",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "- [PyTorch CNN Tutorial](https://github.com/patrickloeber/pytorchTutorial/blob/master/14_cnn.py)\n",
    "- [Writing CNNs from Scratch in PyTorch](https://www.digitalocean.com/community/tutorials/writing-cnns-from-scratch-in-pytorch)\n",
    "- [CIFAR-10 with ResNet in PyTorch](https://medium.com/@thatchawin.ler/cifar10-with-resnet-in-pytorch-a86fe18049df)\n",
    "- [Introduction to Deep Learning (MATLAB Video)](https://www.mathworks.com/videos/introduction-to-deep-learning-what-are-convolutional-neural-networks--1489512765771.html)\n",
    "- [PyTorch Documentation for Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d526936b-7c95-446b-a6a0-ec848fc03582",
   "metadata": {},
   "source": [
    "# Contributions  ü§ù\n",
    "\n",
    "- **Taliya Mira** üë©‚Äçüíª \n",
    "- **Ryam AlMalki** üë©‚Äçüíª   \n",
    "- **Raghad Alsubaie** üë©‚Äçüíª \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cae430e-5fd6-4d5d-ba32-a4d5fa8f712f",
   "metadata": {},
   "source": [
    "# Acknowledgments üôè\n",
    "\n",
    "Thank you, **[Dr. Mustafa M. Youldash](https://www.linkedin.com/in/youldash/)**, for your guidance, wisdom, and endless encouragement. Your support made all the difference, turning this project into something we‚Äôre truly proud of.  \n",
    "\n",
    "You didn‚Äôt just teach us‚Äîyou inspired us to think deeper, work harder, and dream bigger.  \n",
    "\n",
    "We‚Äôll carry your lessons with us, always striving to improve and give our best.  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
